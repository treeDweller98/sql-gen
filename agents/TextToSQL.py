import re
import json
import sqlite3
import warnings
from pathlib import Path
from abc import ABC
from collections.abc import Callable
import pandas as pd
from openai import OpenAI


class TextToSQL(ABC):
    """ Base class for all Text-to-SQL generation agents. """

    def __init__(
            self, model: str, client: OpenAI, get_db_cursor: Callable[[str], sqlite3.Cursor], 
            db_schemas: dict[str, str], output_path: Path, is_debug: bool = False
        ) -> None:
        """ Attributes
            ----------
                model: str
                    Text generation model name.
                client: OpenAI
                    OpenAI client with a valid API key.
                get_db_cursor: Callable[[str], sqlite3.Cursor]
                    Function that takes a db_id (str), connects to db, and returns db cursor.
                db_schemas: dict[str, str]
                    Dictionary of db schemas indexed by db_id
                output_path: Path
                    Path to save all output files
                is_debug: bool
                    Debug mode if True; prints prompt instead of messaging model via API client
                n_prompt_tokens: list[int]
                    Number of input tokens sent in each request
                n_completion_tokens: list[int]
                    Number of output tokens generated by the model for each request
        """
        self.model = model
        self.client = client
        self.get_db_cursor = get_db_cursor
        self.db_schemas = db_schemas
        self.output_path = output_path
        self.n_prompt_tokens: list[int] = []
        self.n_completion_tokens: list[int] = []
        self.is_debug = is_debug
        if is_debug:
            warnings.warn("Debug mode active- agent will only print prompts instead of generating response.")

    def request_model(
            self, messages: list[dict[str, str]],
            temperature: float = 0.7, max_tokens: int = 2048, top_p: float = 1 
        ) -> str:
        """ Messages model using OpenAI client and returns the text generated. Prints prompt in debug mode"""
        if self.is_debug:
            separator = f"\n{'=' * 25}\n\n"
            reply = (
                separator.join(
                    f"{message['role'].upper()}:\n{message['content']}"
                    for message in messages
                )
                + separator
                + "<<MODEL GENERATES RESPONSE HERE>>\n\n"
            )
            print(reply)
        else:
            api_response = self.client.chat.completions.create(
                model = self.model,
                messages = messages, 
                temperature = temperature,
                max_tokens = max_tokens,
                top_p = top_p,
            )
            reply = api_response.choices[0].message.content
            self.n_prompt_tokens.append(api_response.usage.prompt_tokens)
            self.n_completion_tokens.append(api_response.usage.completion_tokens)
        return reply

    def generate_response(self, schema: str, question: str, hint: str) -> str:
        """ Takes a BIRD question, returns the generated raw response containing the final SQL. """
        raise NotImplementedError
    
    def batched_generate(self, df: pd.DataFrame) -> list[str]:
        """ Generates raw responses for a DataFrame of BIRD questions. """
        raise NotImplementedError

    def dump_to_json_on_error(self, raw_responses: list[str]) -> None:
        """ Dumps raw responses into a json file; used in case of errors interrupting batched generation. """
        filepath = self.output_path / f"{self.model}_{self.__class__.__name__}_error_bak.json"
        filepath.parent.mkdir(parents=True, exist_ok=True)
        with open(filepath, 'w') as f:
            json.dump(raw_responses, f, ensure_ascii=False, indent=4)

    def auto_parse_sql_from_response(self, raw_responses: list[str]) -> list[str]:
        """ Takes raw responses and returns the cleaned SQLs extracted using regex. """
        cleaned_sql = []
        for response in raw_responses:
            sql = re.search(r'```sql(.*?)```', response, re.DOTALL).group(1).strip()
            cleaned_sql.append(sql)
        return cleaned_sql
       
    def run_query(self, db_id: str, sql: str) -> list:
        """ Executes SQL query and returns rows. """
        cursor = self.get_db_cursor(db_id)
        cursor = cursor.execute(sql)
        rows = cursor.fetchall()
        return rows
    
    def is_sql_same(self, db_id: str, query_1: str, query_2: str) -> bool:
        """ Executes SQL queries and returns True if outputs match, with no operation errors. """
        try:
            res_1 = self.run_query(db_id, query_1)
            res_2 = self.run_query(db_id, query_2)
        except sqlite3.OperationalError as e:
            print(f"{e.__class__.__name__} {e}")
            return False
        else:
            return set(res_1) == set(res_2)
        
    def calculate_total_generation_cost(self, input_token_cost: float, output_token_cost: float) -> None:
        """ Takes token costs in $/1M and prints the total cost of generation for this agent """
        cost_input  = sum(self.n_prompt_tokens) * (input_token_cost / 1e6)
        cost_output = sum(self.n_completion_tokens) * (output_token_cost / 1e6)
        print(f"{cost_input=: .2f} | {cost_output=: .2f} | Total = ${cost_input + cost_output}")

