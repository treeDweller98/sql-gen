{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from core.EvaluatorForBIRD import EvaluatorForBIRD\n",
    "from agents.ZeroShotAgent import ZeroShotAgent\n",
    "from agents.OptimizerAgent import OptimizerAgent\n",
    "from agents.MultiAgentDiscussion import MultiAgentDiscussion\n",
    "\n",
    "from config import MODEL, EXPERIMENT, OUTPUT_PATH\n",
    "from core.Model import LLM, GenerationConfig\n",
    "from utils import dump_to_json, read_dataset, get_databases, deploy_ollama\n",
    "import api_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahim/Documents/sql-gen/core/Model.py:210: UserWarning: Debug mode OFF: LLM will generate response\n",
      "  warnings.warn(\"Debug mode OFF: LLM will generate response\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling ollama model llama3.2:1b...\n",
      "pulling manifest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pulling 74701a8c35f6: 100%|██████████| 1.32G/1.32G [00:00<00:00, 7.38TB/s]\n",
      "pulling 966de95ca8a6: 100%|██████████| 1.43k/1.43k [00:00<00:00, 12.0MB/s]\n",
      "pulling fcc5a6bec9da: 100%|██████████| 7.71k/7.71k [00:00<00:00, 47.5MB/s]\n",
      "pulling a70ff7e570d9: 100%|██████████| 6.02k/6.02k [00:00<00:00, 55.2MB/s]\n",
      "pulling 4f659a1e86d7: 100%|██████████| 485/485 [00:00<00:00, 2.41MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifying sha256 digest\n",
      "writing manifest\n",
      "success\n",
      "Successfully pulled model llama3.2:1b\n",
      "Client Instantiated: Ollama model llama3.2:1b active at http://localhost:11434/ (status_code=200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from core.Model import SupportedModels, GenerationConfig, LLM\n",
    "\n",
    "\n",
    "llm = LLM(SupportedModels.Ollama.llama_32_1b)\n",
    "cfg = GenerationConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "Here is your code:\n",
    "\n",
    "'''python\n",
    "q1 = \"SELECT T1.CustomerID FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE T1.Segment = 'LAM' AND SUBSTR(T2.Date, 1, 4) = '2012' GROUP BY T1.CustomerID ORDER BY SUM(T2.Consumption) ASC LIMIT 1\"\n",
    "rows = cursor.execute(q1).fetch all\n",
    "'''\n",
    "\n",
    "Does this answer you query?\n",
    "\"\"\"\n",
    "\n",
    "from agents.OptimizerAgent import OptimizerAgent\n",
    "from core.Model import LLM, SupportedModels, GenerationConfig\n",
    "\n",
    "llm = LLM(SupportedModels.Ollama.llama_32_1b)\n",
    "op_agent = OptimizerAgent(llm, None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm:\n",
      " ```sql\n",
      "SELECT \n",
      "    ( SELECT SUM(T2.Consumption)\n",
      "     FROM customers AS T1\n",
      "     INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID\n",
      "     WHERE T1.Segment = 'LAM'\n",
      "         AND SUBSTR(T2.Date, 1, 4) = '2012'\n",
      "         GROUP BY T1.CustomerID\n",
      "     ) AS Q1,\n",
      "    ( SELECT AVG(T2.Consumption)\n",
      "     FROM customers AS T1\n",
      "     INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID\n",
      "     WHERE SUBSTR(T2.Date, 1, 4) = '2013'\n",
      "         AND T1.Segment = 'SME' ) AS Q2\n",
      "```\n",
      "\n",
      "\n",
      "fixed:\n",
      " SELECT \n",
      "    ( SELECT SUM(T2.Consumption)\n",
      "     FROM customers AS T1\n",
      "     INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID\n",
      "     WHERE T1.Segment = 'LAM'\n",
      "         AND SUBSTR(T2.Date, 1, 4) = '2012'\n",
      "         GROUP BY T1.CustomerID\n",
      "     ) AS Q1,\n",
      "    ( SELECT AVG(T2.Consumption)\n",
      "     FROM customers AS T1\n",
      "     INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID\n",
      "     WHERE SUBSTR(T2.Date, 1, 4) = '2013'\n",
      "         AND T1.Segment = 'SME' ) AS Q2\n"
     ]
    }
   ],
   "source": [
    "a = \"\"\"\n",
    "Here is your code:\n",
    "\n",
    "q1 = \"SELECT T1.CustomerID FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE T1.Segment = 'LAM' AND SUBSTR(T2.Date, 1, 4) = '2012' GROUP BY T1.CustomerID ORDER BY SUM(T2.Consumption) ASC LIMIT 1\"\n",
    "\n",
    "q2 = \"SELECT AVG(T2.Consumption) / 12 FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE SUBSTR(T2.Date, 1, 4) = '2013' AND T1.Segment = 'SME'\"\n",
    "\n",
    "Does this answer you query?\n",
    "\"\"\"\n",
    "def make_msg(system_prompt, user_prompt):\n",
    "    return [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ]\n",
    "\n",
    "def match_sql_regex(response):\n",
    "    sql = re.search(r'```sql(.*?)```', response, re.DOTALL)\n",
    "    if sql:\n",
    "        return sql.group(1).strip()\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sql = match_sql_regex(a)\n",
    "if not sql:\n",
    "    system_prompt = f\"Please extract and enclose the SQL query from the text within a```sql <<your response here>>''' tag\"\n",
    "    llm_parsed = llm(make_msg(system_prompt, f\"### Text:\\n{a}\"), GenerationConfig(temperature=0.4))\n",
    "    print('llm:\\n', llm_parsed)\n",
    "    parsed = match_sql_regex(llm_parsed)\n",
    "    print('\\n\\nfixed:\\n',parsed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import ollama\n",
    "from core.Model import SupportedModels\n",
    "\n",
    "model = 'llama3.2:3b'\n",
    "client = ollama.Client(host='http://localhost:11434/', timeout=60) \n",
    "\n",
    "def opull():\n",
    "    print(f\"Pulling ollama model {model}...\")\n",
    "    current_digest, bars = '', {}\n",
    "    for progress in client.pull(model, stream=True):\n",
    "        digest = progress.get('digest', '')\n",
    "        if digest != current_digest and current_digest in bars:\n",
    "            bars[current_digest].close()\n",
    "\n",
    "        if not digest:\n",
    "            print(progress.get('status'))\n",
    "            continue\n",
    "\n",
    "        if digest not in bars and (total := progress.get('total')):\n",
    "            bars[digest] = tqdm(total=total, desc=f'pulling {digest[7:19]}', unit='B', unit_scale=True)\n",
    "\n",
    "        if completed := progress.get('completed'):\n",
    "            bars[digest].update(completed - bars[digest].n)\n",
    "\n",
    "        current_digest = digest\n",
    "    print(f\"Successfully pulled model {model}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    opull()\n",
    "except ollama.ResponseError as e:\n",
    "    raise ValueError(f\"Ollama pull() failed: ({e.__class__.__name__} {e}).\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"An error with Ollama: ({e.__class__.__name__} {e}).\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Model import LLM, GenerationConfig, SupportedModels\n",
    "\n",
    "llm = LLM(SupportedModels.Ollama.llama_32_1b)\n",
    "cfg = GenerationConfig()\n",
    "\n",
    "# system = \"Your job is to extract the SQL query from this piece of text. Place your answer in ```sql ```\"\n",
    "system = \"Correct the given SQL query to ensure it is valid SQLite\"\n",
    "user = \"\"\"\n",
    "```sql\n",
    "SELECT \n",
    "    MAX(CreationDate) AS MaxConsumptionYear\n",
    "FROM \n",
    "    yearmonth\n",
    "WHERE \n",
    "    EXTRACT(YEAR FROM CreationDate) BETWEEN 2020 AND 2023;\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "def make_msg(system_prompt, user_prompt):\n",
    "    return [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ]\n",
    "\n",
    "reply = llm(make_msg(system, user), cfg)\n",
    "print(reply)\n",
    "llm.count_total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/fahim/Documents/sql-gen/results/llama3.2:1b_zeroshot-metaprompt-optimizer/mp_raw.json', 'r') as f:\n",
    "    resp = json.load(f)\n",
    "\n",
    "    for r in resp:\n",
    "        print('_' * 25)\n",
    "        print(r)\n",
    "        print('_' * 25)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 'zero-shot':\n",
    "    print(f\"Experiment: {MODEL}_{EXPERIMENT}\")\n",
    "    \n",
    "    # Setup\n",
    "    df, db_names = read_dataset()\n",
    "    db_schemas   = fetch_BIRD_schemas(db_names)\n",
    "    print(f'{db_names=}, {len(df)=}')\n",
    "    \n",
    "    client = get_openai_client()\n",
    "    agent = ZeroShotAgent(MODEL, client, get_db_cursor, db_schemas, OUTPUT_PATH)\n",
    "    evaluator = EvaluatorForBIRD(get_db_cursor)\n",
    "    \n",
    "    # Generate\n",
    "    raw_responses = agent.batched_generate(df)\n",
    "    dump_to_json('raw_responses', raw_responses)\n",
    "\n",
    "    # Parse\n",
    "    print(\"Finished Generating. Attempting SQL auto-parsing...\")\n",
    "    cleaned_sql = agent.auto_parse_sql_from_response(raw_responses)\n",
    "    dump_to_json('cleaned_sql', cleaned_sql)\n",
    "    print(\"SQL auto-parsing successful\")\n",
    "\n",
    "    # Evaluate\n",
    "    df['prediction'] = cleaned_sql\n",
    "    df['label'] = evaluator.evaluate(df, pred_col_name='prediction')\n",
    "    \n",
    "    # Save results\n",
    "    df.to_json(OUTPUT_PATH / f'{MODEL}_{EXPERIMENT}_df.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o Zero-shot + Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 'optimizer-agent':\n",
    "    print(f\"Experiment: {MODEL}_{EXPERIMENT}\")\n",
    "    \n",
    "    # Setup\n",
    "    df, db_names = read_dataset()\n",
    "    db_schemas   = fetch_BIRD_schemas(db_names)\n",
    "    print(f'{db_names=}, {len(df)=}')\n",
    "    \n",
    "    client = get_openai_client()\n",
    "    agent = OptimizerAgent(MODEL, client, get_db_cursor, db_schemas, OUTPUT_PATH)\n",
    "    evaluator = EvaluatorForBIRD(get_db_cursor)\n",
    "    \n",
    "    # Generate\n",
    "    df = pd.read_json('gpt-4o_zero-shot_df.json')\n",
    "    raw_responses = agent.batched_generate(df)\n",
    "    dump_to_json('raw_responses', raw_responses)\n",
    "\n",
    "    # Parse\n",
    "    print(f\"Finished Generating. Attempting SQL auto-parsing...\")\n",
    "    cleaned_sql = agent.auto_parse_sql_from_response(raw_responses)\n",
    "    dump_to_json('cleaned_sql', cleaned_sql)\n",
    "    print(f\"SQL auto-parsing successful\")\n",
    "\n",
    "    # Evaluate\n",
    "    df['optimized'] = cleaned_sql\n",
    "    df['opt-label'] = evaluator.evaluate(df, pred_col_name='optimized')\n",
    "    \n",
    "    # Save results\n",
    "    df.to_json(OUTPUT_PATH / f'{MODEL}_{EXPERIMENT}_df.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o Multi-Agent Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 'discussion':\n",
    "    print(f\"Experiment: {MODEL}_{EXPERIMENT}\")\n",
    "    \n",
    "    # Setup\n",
    "    df, db_names = read_dataset()\n",
    "    db_schemas   = fetch_BIRD_schemas(db_names)\n",
    "    print(f'{db_names=}, {len(df)=}')\n",
    "\n",
    "    client = get_openai_client()\n",
    "    multi_agent = MultiAgentDiscussion(MODEL, client, get_db_cursor, db_schemas, OUTPUT_PATH)\n",
    "    evaluator = EvaluatorForBIRD(get_db_cursor)\n",
    "\n",
    "\n",
    "    # Generate\n",
    "    raw_responses = multi_agent.batched_generate(df, rounds=3)\n",
    "    dump_to_json('raw_responses', raw_responses)\n",
    "\n",
    "    # Parse\n",
    "    print(f\"Finished Generating. Attempting SQL auto-parse...\")\n",
    "\n",
    "    starter_zero = multi_agent.auto_parse_sql_from_response([response['agent_zero_shot'][0] for response in raw_responses])\n",
    "    dump_to_json('cleaned_zeroshot_starter', starter_zero)\n",
    "\n",
    "    starter_meta = multi_agent.auto_parse_sql_from_response([response['agent_meta_prompt'][0] for response in raw_responses])\n",
    "    dump_to_json('cleaned_starter_meta', starter_meta)\n",
    "    \n",
    "    cleaned_sql  = multi_agent.auto_parse_sql_from_response([response['verdict'] for response in raw_responses])\n",
    "    dump_to_json('cleaned_sql', cleaned_sql)\n",
    "\n",
    "    print(f\"SQL auto-parsing successful\\n\\n\")\n",
    "\n",
    "\n",
    "    # Evaluate results\n",
    "    print(\"Evaluating Zero-shot starter generated queries\")\n",
    "    df['starter_zero_shot'] = starter_zero\n",
    "    df['zero_shot_labels']  = evaluator.evaluate(df, pred_col_name='starter_zero_shot')\n",
    "\n",
    "    print(\"Evaluating meta-prompt starter generated queries\")\n",
    "    df['starter_meta_prompt'] = starter_meta\n",
    "    df['meta_prompt_labels']  = evaluator.evaluate(df, pred_col_name='starter_meta_prompt')\n",
    "\n",
    "    print(\"Evaluating Multi-Agent Discussion generated queries\")\n",
    "    df['prediction'] = cleaned_sql\n",
    "    df['label']      = evaluator.evaluate(df, pred_col_name='prediction')\n",
    "\n",
    "\n",
    "    # Save results\n",
    "    df.to_json(OUTPUT_PATH / f'{MODEL}_{EXPERIMENT}_df.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments:\n",
    "- Zero Shot\n",
    "    - with/without COT\n",
    "- Optimizer (on top of zero-shot)\n",
    "- Multi-agent:\n",
    "    - Zero-shot -> Optimizer -> Multi-agent Debate\n",
    "    - Zero-shot -> Optimizer -> Multi-agent Discussion\n",
    "    - Best of the above -> Optimizer\n",
    "- Decomposition and Generation via Multi-agent Debate/Discussion\n",
    "- Sparse Topology Multi-agent Debate/Discussion\n",
    "- Augmenting schema with LLM calls:\n",
    "    - Point out relationships (graph idea)\n",
    "    - Write short descriptions regarding tables, columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
